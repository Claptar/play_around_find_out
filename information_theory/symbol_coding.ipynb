{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e2bc08",
   "metadata": {},
   "source": [
    "# Set up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda5709",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f78e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Optional, List, Tuple\n",
    "from itertools import count\n",
    "import heapq\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d13a9a",
   "metadata": {},
   "source": [
    "## Helping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "345be475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, prefix=\"\", is_last=True):\n",
    "    \"\"\"Print tree structure as text\"\"\"\n",
    "    if node is None:\n",
    "        return\n",
    "    \n",
    "    # Print current node\n",
    "    connector = \"└── \" if is_last else \"├── \"\n",
    "    if node.symbol:\n",
    "        print(f\"{prefix}{connector}{node.symbol} ({node.weight})\")\n",
    "    else:\n",
    "        print(f\"{prefix}{connector}* ({node.weight})\")\n",
    "    \n",
    "    # Update prefix for children\n",
    "    new_prefix = prefix + (\"    \" if is_last else \"│   \")\n",
    "    \n",
    "    # Print children\n",
    "    if node.left or node.right:\n",
    "        if node.left:\n",
    "            print_tree(node.left, new_prefix, not bool(node.right))\n",
    "        if node.right:\n",
    "            print_tree(node.right, new_prefix, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d247e",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7fc59d",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "This notebook is inpired by information theory [lectures by David McKay](https://www.youtube.com/playlist?list=PLN3p8NUNcClDu1hc2m5cVp8FOEmuF3vRy). I want to implement [Huffman coding algorithm](https://en.wikipedia.org/wiki/Huffman_coding) for data compression and use it to compress [human genome](https://en.wikipedia.org/wiki/Human_genome) sequence. Why doing it? Well, I'm greately facinated by [Arithmetic coding](https://en.wikipedia.org/wiki/Arithmetic_coding) algorithm for data compression and Huffman's algorithm would be great as a beseline to compare to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da187cfc",
   "metadata": {},
   "source": [
    "## Brief overview of related concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb4f91c",
   "metadata": {},
   "source": [
    "### Symbol coding problem\n",
    "\n",
    "In symbol coding problem we have a set of symbols $S = \\{s_1, s_2, \\ldots, s_n\\}$ with probabilities $P = \\{p_1, p_2, \\ldots, p_n\\}$ and we want to encode them using binary strings (codewords) $C = \\{c_1, c_2, \\ldots, c_n\\}$ such that the expected codeword length is minimized. The expected codeword length $L$ is given by:\n",
    "\n",
    "$$\n",
    "L = \\sum_{i=1}^{n} p_i \\cdot l(c_i), \\tag{1}\n",
    "$$\n",
    "\n",
    "where $l(c_i)$ is the length of codeword $c_i$. Let's look at an example to illustrate this.\n",
    "\n",
    "#### Example 1\n",
    "Let's say we have a set of symbols $S = \\{A, B, C, D\\}$ with probabilities $P = \\{0.5, 0.25, 0.125, 0.125\\}$. We want to find the optimal codewords $C$ that minimize the expected codeword length.\n",
    "\n",
    "a) One possible solution is to assign the following codewords:\n",
    "- A: 1000\n",
    "- B: 0100\n",
    "- C: 0010\n",
    "- D: 0001\n",
    "\n",
    "The expected codeword length $L$ is calculated as follows:\n",
    "$$\n",
    "L = \\sum_{i=1}^{n} p_i \\cdot l(c_i) = 0.5 \\cdot 4 + 0.25 \\cdot 4 + 0.125 \\cdot 4 + 0.125 \\cdot 4 = 4\n",
    "$$\n",
    "\n",
    "b) Another possible solution is to assign the following codewords:\n",
    "- A: 1\n",
    "- B: 01\n",
    "- C: 001\n",
    "- D: 0001\n",
    "\n",
    "The expected codeword length $L$ is calculated as follows:\n",
    "$$\n",
    "L = \\sum_{i=1}^{n} p_i \\cdot l(c_i) = 0.5 \\cdot 1 + 0.25 \\cdot 2 + 0.125 \\cdot 3 + 0.125 \\cdot 4 = 1.875\n",
    "$$\n",
    "\n",
    "c) Third possible solution is to assign the following codewords:\n",
    "- A: 1\n",
    "- B: 00\n",
    "- C: 010\n",
    "- D: 10\n",
    "\n",
    "The expected codeword length $L$ is calculated as follows:\n",
    "$$\n",
    "L = \\sum_{i=1}^{n} p_i \\cdot l(c_i) = 0.5 \\cdot 1 + 0.25 \\cdot 2 + 0.125 \\cdot 3 + 0.125 \\cdot 4 = 1.625\n",
    "$$\n",
    "\n",
    "\n",
    "Another thing that is important to mention is that we want our coding to have several useful properties:\n",
    "- **Uniquely decodable**: for any string $x$ and $y$ such that $x \\neq y$ codewords $C(x)$ and $C(y)$ must be different $C(x) \\neq C(y)$. In plain english this means that we can always decode a string of codewords back to the original symbols without ambiguity. In this light, solution (c) in example 1 is not uniquely decodable because the both string `DC` and `ABD` are encoded as $C(DC)=C(ABD) = 10010$.\n",
    "- **Minimal expected codeword length**: we want to minimize the expected codeword length $L$.\n",
    "\n",
    "**Note:** [ASCII](https://en.wikipedia.org/wiki/ASCII) code is another interesting example of symbol coding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3665a49f",
   "metadata": {},
   "source": [
    "### Source coding theorem\n",
    "\n",
    "A question arises: what is the minimum expected codeword length $L$ that we can achieve? The answer is given by [Shannon's source coding theorem](https://en.wikipedia.org/wiki/Shannon%27s_source_coding_theorem) which states that the minimum expected codeword length $L$ is bounded by the entropy $H$ of the source:\n",
    "\n",
    "$$\n",
    "L \\geq H, \\tag{2}\n",
    "$$\n",
    "\n",
    "where the entropy $H$ is defined as:\n",
    "\n",
    "$$\n",
    "H = -\\sum_{i=1}^{n} p_i \\log_2 p_i, \\tag{3}\n",
    "$$\n",
    "\n",
    "This means that no lossless compression scheme can achieve an expected codeword length less than the entropy of the source.\n",
    "\n",
    "By comparing equations (1) and (2) we can see that equality $L = H$ holds when codeword length is equal to $l(c_i) = -\\log_2 p_i$ for all symbols $s_i$. However, this is not always possible because codeword lengths must be integers. Therefore, we can only achieve $L$ that is close to $H$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce7bb51",
   "metadata": {},
   "source": [
    "### Huffman Coding\n",
    "\n",
    "[Huffman coding](https://en.wikipedia.org/wiki/Huffman_coding) is a popular algorithm used for lossless data compression. The basic idea is to assign variable-length codes to input characters, with shorter codes assigned to more frequent characters. This results in a prefix-free binary code, meaning no code is a prefix of any other, which allows for efficient encoding and decoding.\n",
    "\n",
    "The algorithm works by building a binary tree where each leaf node represents a symbol and its probability/frequency. The tree is constructed by repeatedly merging the two nodes with the lowest probabilities until only one node remains, which becomes the root of the tree. The code for each symbol is then determined by traversing the tree from the root to the leaf, assigning a '0' for a left branch and a '1' for a right branch.\n",
    "\n",
    "#### Example 2\n",
    "\n",
    "Consider the \"alphabet\" from previous example, where symbol probabilities are\n",
    "\n",
    "```text\n",
    "A: 0.5\n",
    "B: 0.25\n",
    "C: 0.125\n",
    "D: 0.125\n",
    "```\n",
    "\n",
    "Then the binary tree for this alphabet would look like this:\n",
    "\n",
    "```text\n",
    "        *\n",
    "       / \\\n",
    "      /   \\\n",
    "     *     A(0.5)\n",
    "    / \\\n",
    "   /   \\\n",
    "B(0.25) *\n",
    "       / \\\n",
    "      /   \\\n",
    "  C(0.125) D(0.125)\n",
    "```\n",
    "\n",
    "The algorithm assigns codes by traversing from root to leaf: left=0, right=1. So the resulting code for each symbol would be:\n",
    "\"\n",
    "```text\n",
    "A: 1\n",
    "B: 01\n",
    "C: 001\n",
    "D: 000\n",
    "```\n",
    "\n",
    "An average code length $L$ can be calculated as follows:\n",
    "\n",
    "$$\n",
    "L = \\sum_{i=1}^4 p_i \\cdot l_i = \\frac{1}{2} \\cdot 1 + \\frac{1}{4} \\cdot 2 + \\frac{1}{8} \\cdot 3 + \\frac{1}{8} \\cdot 3  = 1.75\n",
    "$$\n",
    "\n",
    "For comparison, entropy $H$ can be calculated as follows:\n",
    "\n",
    "$$\n",
    "H = - \\sum_{i=1}^4 p_i \\cdot \\log_2p_i = \\frac{1}{2} \\log_22 + \\frac{1}{4} \\log_24 + \\frac{1}{8} \\log_28 + \\frac{1}{8} \\log_28 = 1.75\n",
    "$$\n",
    "\n",
    "As we can see, the average code length $L$ is equal to the entropy $H$ for this particular example. This is a special case and may not hold for all probability distributions, but it illustrates the relationship between Huffman coding and entropy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba9acb",
   "metadata": {},
   "source": [
    "### Heap\n",
    "\n",
    "A heap is a specialized tree-based data structure that satisfies the heap property. In a min-heap, for example, the key at a parent node is always less than or equal to the keys of its children, and the smallest key is at the root. This property makes heaps useful for implementing priority queues, where the highest (or lowest) priority element can be efficiently accessed.\n",
    "\n",
    "#### Operation cost\n",
    "\n",
    "The time complexity for the main operations on a heap is as follows:\n",
    "\n",
    "- Insertion: O(log n)\n",
    "- Deletion (removing the root): O(log n)\n",
    "- Accessing the minimum element: O(1)\n",
    "\n",
    "#### Example 3\n",
    "\n",
    "Let's use a min-heap to illustrate the heap property. Consider the following sequence of numbers: 5, 3, 8, 1, 4. We can insert these numbers into a min-heap as follows:\n",
    "```text\n",
    "1. Insert 5:       5\n",
    "2. Insert 3:       3\n",
    "                  /\n",
    "                 5\n",
    "3. Insert 8:       3\n",
    "                  / \\\n",
    "                 5   8\n",
    "4. Insert 1:       1\n",
    "                  / \\\n",
    "                 3   8\n",
    "                /\n",
    "               5\n",
    "5. Insert 4:       1\n",
    "                  / \\\n",
    "                 3   4\n",
    "                / \\\n",
    "               5   8\n",
    "6. Remove 1:       3\n",
    "                  / \\\n",
    "                 5   4\n",
    "                /\n",
    "               8\n",
    "```\n",
    "In this min-heap, the smallest element (1) is at the root, and the heap property is maintained at each level.\n",
    "\n",
    "Let's use `heapq` in Python to demonstrate heap operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00124219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heap: [1, 3, 8, 5, 4]\n",
      "Removed smallest element: 1\n",
      "Heap after removal: [3, 4, 8, 5]\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "# Create a min-heap\n",
    "heap = []\n",
    "\n",
    "# Insert elements into the heap\n",
    "heapq.heappush(heap, 5)\n",
    "heapq.heappush(heap, 3)\n",
    "heapq.heappush(heap, 8)\n",
    "heapq.heappush(heap, 1)\n",
    "heapq.heappush(heap, 4)\n",
    "\n",
    "# Display the heap\n",
    "print(\"Heap:\", heap)\n",
    "\n",
    "# Remove the smallest element\n",
    "smallest = heapq.heappop(heap)\n",
    "print(\"Removed smallest element:\", smallest)\n",
    "print(\"Heap after removal:\", heap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e392ac56",
   "metadata": {},
   "source": [
    "# Let's play around"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75da32a7",
   "metadata": {},
   "source": [
    "## Huffman coding algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadcb871",
   "metadata": {},
   "source": [
    "### Description \n",
    "\n",
    "Huffman coding algorithm follows these steps:\n",
    "\n",
    "1. Build a priority queue (min-heap) of nodes, where each node represents a symbol and its frequency.\n",
    "2. While there is more than one node in the queue:\n",
    "   a. Remove the two nodes of lowest frequency from the queue.\n",
    "   b. Create a new internal node with these two nodes as children and a frequency equal to the sum of their frequencies.\n",
    "   c. Insert the new node back into the queue.\n",
    "3. The remaining node is the root of the Huffman tree.\n",
    "4. Traverse the tree to generate the Huffman codes for each symbol.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d87e9f",
   "metadata": {},
   "source": [
    "### Implement a binary-tree class\n",
    "\n",
    "Binary tree is an essential data structure for this algorithm. It is a hierarchical structure where each node has at most two children. In the context of Huffman coding, each leaf node represents a symbol and its probability/frequency, while internal nodes represent the combined frequency of their child nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf0220b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Node:\n",
    "    weight: float                   # weight of the node (frequency or probability)\n",
    "    symbol: Optional[str] = None    # symbol for leaf nodes\n",
    "    left: Optional[\"Node\"] = None   # left child\n",
    "    right: Optional[\"Node\"] = None  # right child"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9300c46c",
   "metadata": {},
   "source": [
    "Let's build a huffman tree from example above\n",
    "\n",
    "\n",
    "```text\n",
    "        *\n",
    "       / \\\n",
    "      /   \\\n",
    "     *     A(0.5)\n",
    "    / \\\n",
    "   /   \\\n",
    "B(0.25) *\n",
    "       / \\\n",
    "      /   \\\n",
    "  C(0.125) D(0.125)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aec2b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree structure:\n",
      "└── * (1.0)\n",
      "    ├── * (0.5)\n",
      "    │   ├── B (0.25)\n",
      "    │   └── * (0.25)\n",
      "    │       ├── C (0.125)\n",
      "    │       └── D (0.125)\n",
      "    └── A (0.5)\n"
     ]
    }
   ],
   "source": [
    "# Create leaf nodes\n",
    "node_A = Node(weight=0.5, symbol=\"A\")\n",
    "node_B = Node(weight=0.25, symbol=\"B\") \n",
    "node_C = Node(weight=0.125, symbol=\"C\")\n",
    "node_D = Node(weight=0.125, symbol=\"D\")\n",
    "\n",
    "# Create internal nodes (bottom-up)\n",
    "# Right internal node: combines C and D\n",
    "right_internal = Node(weight=0.25, left=node_C, right=node_D)\n",
    "\n",
    "# Left internal node: combines B and the right internal node  \n",
    "left_internal = Node(weight=0.5, left=node_B, right=right_internal)\n",
    "\n",
    "# Root node: combines left internal node and A\n",
    "root = Node(weight=1.0, left=left_internal, right=node_A)\n",
    "\n",
    "# Visualise\n",
    "print(\"Tree structure:\")\n",
    "print_tree(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d064f900",
   "metadata": {},
   "source": [
    "### Build a Huffman Tree\n",
    "\n",
    "To efficiently manage the nodes, we'll use a priority queue (min-heap) to store and retrieve the nodes based on their frequencies. This allows us to quickly access the least frequent nodes when building the tree. The algorithm works by repeatedly merging the two least frequent nodes until only one node remains, which becomes the root of the Huffman tree. Schematic representation of the process:\n",
    "\n",
    "#### Example 4\n",
    "\n",
    "Let's use the following symbols and their frequencies:\n",
    "\n",
    "- A: 0.5\n",
    "- B: 0.25\n",
    "- C: 0.125\n",
    "- D: 0.125\n",
    "\n",
    "1. Create all leaf nodes for our future tree\n",
    "    ```python\n",
    "    Node(A, 0.5)\n",
    "    Node(B, 0.25)\n",
    "    Node(C, 0.125)\n",
    "    Node(D, 0.125)\n",
    "    ```\n",
    "2. Create a priority queue (min-heap) and insert all leaf nodes:\n",
    "    ```python\n",
    "    min_heap = [Node(A, 0.5), Node(B, 0.25), Node(C, 0.125), Node(D, 0.125)]\n",
    "    ```\n",
    "\n",
    "3. Extract the two least frequent nodes:\n",
    "    ```python\n",
    "    left = extract_min(min_heap) # Node(C, 0.125)\n",
    "    right = extract_min(min_heap) # Node(D, 0.125)\n",
    "    ```\n",
    "\n",
    "4. Create a new internal node with these two nodes as children and their combined frequency:\n",
    "    ```python\n",
    "    new_node = Node(None, left.frequency + right.frequency, left, right)\n",
    "    ```\n",
    "\n",
    "5. Insert the new node back into the priority queue:\n",
    "    ```python\n",
    "    insert(min_heap, new_node) # [Node(B, 0.25), Node(A, 0.5), Node(None, 0.25, Node(C, 0.125), Node(D, 0.125))]\n",
    "    ```\n",
    "\n",
    "6. Repeat steps 3-5 until only one node remains in the priority queue. This node will be the root of the Huffman tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e24a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_huffman_tree(weights: Dict[str, float]) -> Optional[Node]:\n",
    "    \"\"\"\n",
    "    Build a Huffman tree from the given symbol weights\n",
    "    \"\"\"\n",
    "    # Check that weights are > 0\n",
    "    items = [(float(w), str(s)) for s, w in weights.items() if float(w) > 0.0]\n",
    "    if not items:\n",
    "        return None\n",
    "\n",
    "    # Sort items by weight to make code deterministic (important for decoding)\n",
    "    items.sort(key=lambda x: (x[0], x[1]))\n",
    "\n",
    "    # Build the tree using a min-heap\n",
    "    uid = count()                                   # unique integer 0,1,2,...\n",
    "    heap = [(w, next(uid), Node(weight=w, symbol=s))   # (weight, tie_id, tree)\n",
    "            for (w, s) in items]\n",
    "    heapq.heapify(heap)\n",
    "\n",
    "    # Handle single-symbol edge case\n",
    "    if len(heap) == 1:\n",
    "        w, _, leaf = heapq.heappop(heap)\n",
    "        return Node(weight=w, left=leaf)\n",
    "\n",
    "    # Build the tree\n",
    "    while len(heap) > 1:\n",
    "        w1, _, n1 = heapq.heappop(heap)             # smallest\n",
    "        w2, _, n2 = heapq.heappop(heap)             # 2nd smallest\n",
    "        parent = Node(weight=w1 + w2, left=n1, right=n2)\n",
    "        heapq.heappush(heap, (parent.weight, next(uid), parent))\n",
    "\n",
    "    return heap[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4422b9",
   "metadata": {},
   "source": [
    "Now we can apply the algorithm to build the Huffman tree and generate the codes for each symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0fcebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huffman Tree structure:\n",
      "└── * (1.0)\n",
      "    ├── A (0.5)\n",
      "    └── * (0.5)\n",
      "        ├── B (0.25)\n",
      "        └── * (0.25)\n",
      "            ├── C (0.125)\n",
      "            └── D (0.125)\n"
     ]
    }
   ],
   "source": [
    "probabilities = {\n",
    "    'A': 0.5,\n",
    "    'B': 0.25,\n",
    "    'C': 0.125,\n",
    "    'D': 0.125\n",
    "}\n",
    "\n",
    "root = build_huffman_tree(probabilities)\n",
    "print(\"Huffman Tree structure:\")\n",
    "print_tree(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed75de47",
   "metadata": {},
   "source": [
    "### Derive codes\n",
    "\n",
    "To derive codes from Huffman tree we will use a recursive traversal of the tree. Starting from the root, we will traverse to the left child by appending '0' to the current code and to the right child by appending '1'. When we reach a leaf node, we will record the symbol and its corresponding code. This is essentially a depth-first search (DFS) of the tree.\n",
    "\n",
    "Schematic representation of the process:\n",
    "\n",
    "1. Start at the root with an empty code:\n",
    "   ```python\n",
    "   current_code = \"\"\n",
    "   ```\n",
    "\n",
    "2. Traverse the tree:\n",
    "   - If the current node is a leaf, record the symbol and its code:\n",
    "     ```python\n",
    "     if node is leaf:\n",
    "         codes[node.symbol] = current_code\n",
    "     ```\n",
    "\n",
    "   - If the current node is not a leaf, traverse left and right:\n",
    "     ```python\n",
    "     traverse(node.left, current_code + \"0\")\n",
    "     traverse(node.right, current_code + \"1\")\n",
    "     ```\n",
    "\n",
    "The final codes dictionary will contain the Huffman codes for all symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0494c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codes_from_tree(root: Optional[Node]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Derive binary codes from the Huffman tree\n",
    "    \"\"\"\n",
    "    # Return empty dictionary if root is None\n",
    "    if root is None:\n",
    "        return {}\n",
    "\n",
    "    # Create a dictionary to hold the codes\n",
    "    codes: Dict[str, str] = {}\n",
    "\n",
    "    # Depth-first search (DFS) to traverse the tree\n",
    "    def dfs(n: Node, path: str):\n",
    "        if n.symbol is not None:                 # leaf node found\n",
    "            codes[n.symbol] = path or \"0\"        # assign code\n",
    "            return\n",
    "        if n.left:  dfs(n.left,  path + \"0\") # go left, add \"0\"\n",
    "        if n.right: dfs(n.right, path + \"1\") # go right, add \"1\"\n",
    "\n",
    "    # Start DFS traversal from the root\n",
    "    dfs(root, \"\")\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9978bb",
   "metadata": {},
   "source": [
    "Now we can apply this algorithm to generate the Huffman codes for each symbol from the constructed Huffman tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e2a3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huffman Codes: {'A': '0', 'B': '10', 'C': '110', 'D': '111'}\n"
     ]
    }
   ],
   "source": [
    "codes = codes_from_tree(root)\n",
    "print(\"Huffman Codes:\", codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba9fe0f",
   "metadata": {},
   "source": [
    "As you can see the code is very similar to the one we got in [Exercise 2](#example-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61b8c2d",
   "metadata": {},
   "source": [
    "### Compare entropy and expected length\n",
    "\n",
    "Although we have already compared entropy and expected length in Exercise 2. Let's create functions to compute both values for future examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3add998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(probabilities: Dict[str, float]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a set of symbol probabilities\n",
    "    \"\"\"\n",
    "    p = np.array(list(probabilities.values()))\n",
    "    return -np.sum(p * np.log2(p, where=(p > 0)))\n",
    "\n",
    "def expected_length(coding: Dict[str, str], probabilities: Dict[str, float]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the expected length of a set of symbol codes\n",
    "    \"\"\"\n",
    "    keys = coding.keys()\n",
    "    p = np.array([probabilities.get(symbol, 0) for symbol in keys])\n",
    "    length = np.array([len(coding[symbol]) for symbol in keys])\n",
    "    return np.sum(length * p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e55ed10",
   "metadata": {},
   "source": [
    "Now let's print the summary for our example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6206f021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol Probabilities: {'A': 0.5, 'B': 0.25, 'C': 0.125, 'D': 0.125}\n",
      "Huffman Codes: {'A': '0', 'B': '10', 'C': '110', 'D': '111'}\n",
      "Huffman tree from weights:\n",
      "└── * (1.0)\n",
      "    ├── A (0.5)\n",
      "    └── * (0.5)\n",
      "        ├── B (0.25)\n",
      "        └── * (0.25)\n",
      "            ├── C (0.125)\n",
      "            └── D (0.125)\n",
      "Entropy: 1.75\n",
      "Expected Length: 1.75\n"
     ]
    }
   ],
   "source": [
    "print(\"Symbol Probabilities:\", probabilities)\n",
    "print(\"Huffman Codes:\", codes)\n",
    "print(\"Huffman tree from weights:\")\n",
    "print_tree(root)\n",
    "print(\"Entropy:\", entropy(probabilities))\n",
    "print(\"Expected Length:\", expected_length(codes, probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a361fa2",
   "metadata": {},
   "source": [
    "### Convert a string of charachters to bytes\n",
    "\n",
    "Let's create a function to convert a string to bytes and compare the size of our byte representation to ASCII and UTF-8 encodings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d68dc472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bits2bytes(bits: str):\n",
    "    \"\"\"\n",
    "    Convert a string of bits to bytes\n",
    "    \"\"\"\n",
    "    # Pad the bit string to make its length a multiple of 8\n",
    "    paddlen = (8 - len(bits) % 8) % 8\n",
    "    padded_bits = bits + '0' * paddlen\n",
    "\n",
    "    # Convert each group of 8 bits to a byte\n",
    "    byte_array = bytearray()\n",
    "    for i in range(0, len(padded_bits), 8):\n",
    "        byte = padded_bits[i:i + 8]\n",
    "        byte_array.append(int(byte, 2))\n",
    "    return bytes(byte_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece6a718",
   "metadata": {},
   "source": [
    "Now let's generate a string of characters from our distribution and generate a bit and byte string representations:\n",
    "\n",
    "```text\n",
    "A: 0.5\n",
    "B: 0.25\n",
    "C: 0.125\n",
    "D: 0.125\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4367ad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated string: DBDBBADAAACACDABAAADADCCAABABABDBAABBBABABCAABBABB...\n",
      "Character counts: {'A': 481, 'B': 264, 'C': 120, 'D': 135}\n",
      "Character frequencies: {'A': 0.481, 'B': 0.264, 'C': 0.12, 'D': 0.135}\n"
     ]
    }
   ],
   "source": [
    "# fix random seed\n",
    "np.random.seed(4)\n",
    "\n",
    "# generate string\n",
    "n = 1000\n",
    "char_list = list(probabilities.keys())\n",
    "prob_list = list(probabilities.values())\n",
    "string = \"\".join(np.random.choice(char_list, p=prob_list, size=n))\n",
    "print(f\"Generated string: {string[:50]}...\")\n",
    "\n",
    "# calculate frequency\n",
    "freq = {char: string.count(char) for char in char_list}\n",
    "print(\"Character counts:\", freq)\n",
    "print(\"Character frequencies:\", {char: freq[char] / n for char in char_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "911f6196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huffman encoding size (bits): 1774\n",
      "Huffman encoding size (bytes): 222\n",
      "UTF-8 encoding size (bytes): 1000\n",
      "UTF-16 encoding size (bytes): 2002\n",
      "ASCII encoding size (bytes): 1000\n"
     ]
    }
   ],
   "source": [
    "# encode the string using different encoding schemes\n",
    "huffman_bits = \"\".join([codes.get(char) for char in string])\n",
    "huffman_bytes = bits2bytes(huffman_bits)\n",
    "utf8_bytes = string.encode('utf-8')\n",
    "utf16_bytes = string.encode('utf-16')\n",
    "ascii_bytes = string.encode('ascii')\n",
    "\n",
    "# print sizes\n",
    "print(\"Huffman encoding size (bits):\", len(huffman_bits))\n",
    "print(\"Huffman encoding size (bytes):\", len(huffman_bytes))\n",
    "print(\"UTF-8 encoding size (bytes):\", len(utf8_bytes))\n",
    "print(\"UTF-16 encoding size (bytes):\", len(utf16_bytes))\n",
    "print(\"ASCII encoding size (bytes):\", len(ascii_bytes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
